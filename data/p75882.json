{"dataset":"articles","provider":"pursuit","banner_url":"https://pursuit.unimelb.edu.au/__data/assets/image/0037/75889/AI-apocalypse-or-overblown-hype_78a0e854-29a1-4c5d-b6d3-98b168e1e786.jpg","id":"75882","text":"<div class=\"container\"><span><p>The <a href=\"https://pursuit.unimelb.edu.au/articles/what-ll-be-big-in-2023-ai-that-s-what\" target=\"_self\">tidal wave</a> of predictions that generative artificial intelligence (AI) created last year shows no signs of abating.</p><p>Social media, <a href=\"https://www.afr.com/technology/aussie-vcs-ready-for-the-next-tech-boom-generative-ai-20230112-p5cc7w\" target=\"_self\">traditional media</a> and water cooler conversations are awash with predictions about AI’s implications, including the risks and dangers of so-called <a href=\"https://machinelearningmastery.com/what-are-large-language-models/\" target=\"_self\">large language models</a> like ChatGPT.</p></span><div class=\"container\" data-v-012796f8><figure class=\"ps-figure\" data-v-012796f8><img loading=\"lazy\" class=\"ps-figure__image\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://pursuit.unimelb.edu.au/__data/assets/image/0037/75889/varieties/64w.jpg 64w,https://pursuit.unimelb.edu.au/__data/assets/image/0037/75889/varieties/160w.jpg 160w,https://pursuit.unimelb.edu.au/__data/assets/image/0037/75889/varieties/375w.jpg 375w,https://pursuit.unimelb.edu.au/__data/assets/image/0037/75889/varieties/768w.jpg 768w,https://pursuit.unimelb.edu.au/__data/assets/image/0037/75889/varieties/960w.jpg 960w,https://pursuit.unimelb.edu.au/__data/assets/image/0037/75889/varieties/1280w.jpg 1280w,https://pursuit.unimelb.edu.au/__data/assets/image/0037/75889/varieties/1440w.jpg 1440w,https://pursuit.unimelb.edu.au/__data/assets/image/0037/75889/varieties/1920w.jpg 1920w\" src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0037/75889/AI-apocalypse-or-overblown-hype_78a0e854-29a1-4c5d-b6d3-98b168e1e786.jpg\" alt   data-v-012796f8><figcaption class=\"ps-figure__caption\" data-v-012796f8>There are many predictions out there about AI’s implications, including the risks of so-called large language models. Picture: Getty Images</figcaption></figure></div><span><p>Soothsayers are having a field day with headlines like “<a href=\"https://timdenning.com/chatgpt/\" target=\"_self\">Open AI’s ChatGPT will change the world</a>”; “First <a href=\"https://youtu.be/ulRpVkPoeWA\" target=\"_self\">your job</a>, and then <a href=\"https://www.forbes.com/sites/mikeosullivan/2023/03/11/will-ai-take-over-the-world/?sh=7112157d11df&utm_source=ForbesMainTwitter&utm_campaign=socialflowForbesMainTwitter&utm_medium=social\" target=\"_self\">your life</a>!”; and “30 ways for your business to survive the <a href=\"https://www.forbes.com/sites/jodiecook/2023/05/10/3-things-businesses-must-do-to-avoid-becoming-irrelevant-in-the-ai-revolution/?sh=34a4187548da\" target=\"_self\">AI revolution</a>”.</p><p>Some countries are acting over concerns about generative AI. <a href=\"https://www.bbc.com/news/technology-65139406\" target=\"_self\">Italy temporarily banned ChatGPT</a> over privacy concerns. <a href=\"https://www.livemint.com/technology/tech-news/from-china-to-syria-here-s-a-list-of-countries-that-have-banned-chatgpt-know-why-11680531688656.html\" target=\"_self\">It is blocked</a> in China, Iran and Syria.</p><p>Other AI luminaries are also expressing concern. <a href=\"https://en.wikipedia.org/wiki/Geoffrey_Hinton\" target=\"_self\">AI pioneer Geoffrey Hinton</a> resigned from Google so that he could speak freely about the technology’s dangers.</p></span><!--[--><!--noindex--><article class=\"ps-cta container\" data-component=\"CallToAction\" data-v-1d83364b><div class=\"ps-cta__flex\" data-v-1d83364b><div data-v-1d83364b><img src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0019/77302/varieties/375w.jpg\" data-v-1d83364b></div></div><div class=\"ps-cta__info\" data-v-1d83364b><div class=\"ps-cta__top\" data-v-1d83364b><p class=\"ps-cta__channel ps-ff-source-sans-pro ps-fw-semibold ps-text-uppercase\" data-v-1d83364b>Sciences &amp; Technology</p></div><a class=\"ps-cta__link ps-ff-source-sans-pro ps-fw-semibold ps-lh-120 ps-cta__black\" href=\"https://pursuit.unimelb.edu.au/articles/what-ll-be-big-in-2023-ai-that-s-what?in_c=in_article_cta\" target=\"_self\" data-v-1d83364b><p data-v-1d83364b>What’ll be big in 2023? AI, that’s what <i class=\"ps-icon--arrow-right ps-cta__black\" data-v-1d83364b></i></p></a></div></article><!--endnoindex--><!--]--><span><p>“I don’t think they should scale this up more until they have understood whether they can control it,” <a href=\"https://www.computerworld.com/article/3697014/ethics-what-ethics-for-microsoft-its-full-speed-ahead-on-ai.html\" target=\"_self\">Hinton said</a>.</p><p>Hinton’s remarks followed an <a href=\"https://futureoflife.org/open-letter/pause-giant-ai-experiments/\" target=\"_self\">open letter</a> signed by another ‘Godfather of AI’, <a href=\"https://yoshuabengio.org/\" target=\"_self\">Yoshua Bengio</a>, as well as Elon Musk and others, which called for a pause on the development of AI models more advanced than GPT-4.</p><p>More recently, Samuel Altman from OpenAI <a href=\"https://edition.cnn.com/2023/05/17/tech/sam-altman-congress/index.html\" target=\"_self\">appealed to US lawmakers</a> for greater regulation to prevent <a href=\"https://www.wsj.com/articles/chatgpts-sam-altman-faces-senate-panel-examining-artificial-intelligence-4bb6942a\" target=\"_self\">AI’s possible harms</a>.</p><p>Of course, many individuals and Big Tech companies contend that AI can be a force for good. For example, AI might provide <a href=\"https://www.jasper.ai/\" target=\"_self\">creative assistance</a> in writing and image generation. Professionals in many sectors are already integrating tools like Google’s <a href=\"https://blog.google/technology/ai/google-bard-updates-io-2023/\" target=\"_self\">Bard</a> into their work.</p></span><div class=\"container\" data-v-012796f8><figure class=\"ps-figure\" data-v-012796f8><img loading=\"lazy\" class=\"ps-figure__image\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://pursuit.unimelb.edu.au/__data/assets/image/0030/75891/varieties/64w.jpg 64w,https://pursuit.unimelb.edu.au/__data/assets/image/0030/75891/varieties/160w.jpg 160w,https://pursuit.unimelb.edu.au/__data/assets/image/0030/75891/varieties/375w.jpg 375w,https://pursuit.unimelb.edu.au/__data/assets/image/0030/75891/varieties/768w.jpg 768w,https://pursuit.unimelb.edu.au/__data/assets/image/0030/75891/varieties/960w.jpg 960w,https://pursuit.unimelb.edu.au/__data/assets/image/0030/75891/varieties/1280w.jpg 1280w,https://pursuit.unimelb.edu.au/__data/assets/image/0030/75891/varieties/1440w.jpg 1440w,https://pursuit.unimelb.edu.au/__data/assets/image/0030/75891/varieties/1920w.jpg 1920w\" src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0030/75891/AI-apocalypse-or-overblown-hype_132e873a-12d0-4a4a-a939-4aacf38ea329.jpg\" alt   data-v-012796f8><figcaption class=\"ps-figure__caption\" data-v-012796f8>Samuel Altman, CEO of OpenAI, before the Senate Judiciary Subcommittee on Privacy, Technology, and the Law. Picture: Getty Images</figcaption></figure></div><span><p>All the hubbub raises the question: are we truly at an AI turning point? Is it the beginning of the end for humanity or a <a href=\"https://techbuzzireland.com/2023/04/24/ai-just-another-fad-probably-not/\" target=\"_self\">passing fad</a>? Should we be worried about emerging AI, and if so, why?</p><p>Whichever way you slice the silicon, things are changing fast. We’re unlikely to put the genie back in the bottle, so we need to understand and, where possible, mitigate the risks.</p><p>There are two camps of thinkers with different takes on AI’s immediate and longer-term risks – the ‘AI Alignment’ (safety first) and ‘AI Ethics’ (social justice) camps.</p></span><!--[--><!--noindex--><article class=\"ps-cta container\" data-component=\"CallToAction\" data-v-1d83364b><div class=\"ps-cta__flex\" data-v-1d83364b><div data-v-1d83364b><img src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0031/78709/varieties/375w.jpg\" data-v-1d83364b></div></div><div class=\"ps-cta__info\" data-v-1d83364b><div class=\"ps-cta__top\" data-v-1d83364b><p class=\"ps-cta__channel ps-ff-source-sans-pro ps-fw-semibold ps-text-uppercase\" data-v-1d83364b>Sciences &amp; Technology</p></div><a class=\"ps-cta__link ps-ff-source-sans-pro ps-fw-semibold ps-lh-120 ps-cta__black\" href=\"https://pursuit.unimelb.edu.au/articles/is-sentience-really-the-debate-to-have?in_c=in_article_cta\" target=\"_self\" data-v-1d83364b><p data-v-1d83364b>Is sentience really the debate to have? <i class=\"ps-icon--arrow-right ps-cta__black\" data-v-1d83364b></i></p></a></div></article><!--endnoindex--><!--]--><span><h2 class=\"center\">Ai alignment – death, self-interest and superintelligence</h2></span><span><p>Some people – like Musk, Hinton and Altman – fear that AI could be turned into a <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10030838/\" target=\"_self\">weapon of mass destruction</a> by <a href=\"https://www.cnbc.com/2017/09/04/putin-leader-in-artificial-intelligence-will-rule-world.html\" target=\"_self\">autocrats or nations</a>.</p><p>They also worry about AI’s own agency. No matter how carefully AI is programmed, these people think we may inadvertently design algorithms (‘Misaligned AI’) that <a href=\"https://cepr.org/voxeu/columns/ai-and-paperclip-problem\" target=\"_self\">relentlessly pursue goals</a> contrary to our interests.</p><p>Sometimes AI’s harms will be relatively localised – though still significant – like when AI replaces human workers or even <a href=\"https://www.9news.com.au/national/jobs-ai-will-replace-technology/dcaf8d90-14cb-426e-8605-712555ad4995\" target=\"_self\">eliminates industries</a>.</p><p>But their largest concern is that AI could get smart enough to threaten humanity itself.</p></span><div class=\"container\" data-v-012796f8><figure class=\"ps-figure\" data-v-012796f8><img loading=\"lazy\" class=\"ps-figure__image\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://pursuit.unimelb.edu.au/__data/assets/image/0036/75888/varieties/64w.jpg 64w,https://pursuit.unimelb.edu.au/__data/assets/image/0036/75888/varieties/160w.jpg 160w,https://pursuit.unimelb.edu.au/__data/assets/image/0036/75888/varieties/375w.jpg 375w,https://pursuit.unimelb.edu.au/__data/assets/image/0036/75888/varieties/768w.jpg 768w,https://pursuit.unimelb.edu.au/__data/assets/image/0036/75888/varieties/960w.jpg 960w,https://pursuit.unimelb.edu.au/__data/assets/image/0036/75888/varieties/1280w.jpg 1280w,https://pursuit.unimelb.edu.au/__data/assets/image/0036/75888/varieties/1440w.jpg 1440w,https://pursuit.unimelb.edu.au/__data/assets/image/0036/75888/varieties/1920w.jpg 1920w\" src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0036/75888/AI-apocalypse-or-overblown-hype_44ff32fd-5c60-40a3-b2e9-e7c1fe7b1740.jpg\" alt   data-v-012796f8><figcaption class=\"ps-figure__caption\" data-v-012796f8>Professor Nick Bostrom is the director of the Future of Humanity Institute at Oxford University. Picture: Getty Images</figcaption></figure></div><span><p>According to these and other AI <a href=\"https://www.safe.ai/statement-on-ai-risk#open-letter\" target=\"_self\">experts</a>, “mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.”</p><p><a href=\"https://www.bbc.com/news/world-us-canada-65452940\" target=\"_self\">Hinton likened emerging AI</a> to having “10,000 people and whenever one person learnt something, everybody automatically knew it. And that’s how these chatbots can know so much more than any one person.”</p></span><!--[--><!--noindex--><article class=\"ps-cta container\" data-component=\"CallToAction\" data-v-1d83364b><div class=\"ps-cta__flex\" data-v-1d83364b><div data-v-1d83364b><img src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0022/76117/varieties/375w.jpg\" data-v-1d83364b></div></div><div class=\"ps-cta__info\" data-v-1d83364b><div class=\"ps-cta__top\" data-v-1d83364b><p class=\"ps-cta__channel ps-ff-source-sans-pro ps-fw-semibold ps-text-uppercase\" data-v-1d83364b>Sciences &amp; Technology</p></div><a class=\"ps-cta__link ps-ff-source-sans-pro ps-fw-semibold ps-lh-120 ps-cta__black\" href=\"https://pursuit.unimelb.edu.au/articles/we-need-to-retain-research-integrity-in-the-ai-era?in_c=in_article_cta\" target=\"_self\" data-v-1d83364b><p data-v-1d83364b>We need to retain research integrity in the AI era <i class=\"ps-icon--arrow-right ps-cta__black\" data-v-1d83364b></i></p></a></div></article><!--endnoindex--><!--]--><span><p>Thinkers like Swedish philosopher <a href=\"https://nickbostrom.com/\" target=\"_self\">Professor Nick Bostrom</a> believe that in the not-too-distant future, AI may not only match human intelligence but far outstrip it, leading to a <a href=\"https://www.amazon.com.au/Superintelligence-Dangers-Strategies-Nick-Bostrom-ebook/dp/B00LOOCGB2\" target=\"_self\">dangerous superintelligence</a>.</p><p>But other experts regard the risks of an AI apocalypse as “<a href=\"https://japantoday.com/category/tech/human-extinction-threat-'overblown'-says-ai-sage-marcus\" target=\"_self\">overblown</a>.”</p><p>AI’s history reveals sharp jumps in technological capabilities that apparently heralded unlimited growth. Historically, these jumps have been bookended by long <a href=\"https://en.wikipedia.org/wiki/AI_winter\" target=\"_self\">AI winters</a> where progress slows considerably.</p><p>However, some suspect that this time will be different.</p></span><span><h2 class=\"center\">Ai ethics – prejudice and misinformation</h2></span><span><p>People in the ‘AI Ethics’ camp focus on the social justice implications of AI. <a href=\"https://www.weforum.org/agenda/2022/10/open-source-data-science-bias-more-ethical-ai-technology/\" target=\"_self\">Algorithms with subtle biases</a> are already seeping into everyday life.</p></span><div class=\"container\" data-v-012796f8><figure class=\"ps-figure\" data-v-012796f8><img loading=\"lazy\" class=\"ps-figure__image\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://pursuit.unimelb.edu.au/__data/assets/image/0029/75890/varieties/64w.jpg 64w,https://pursuit.unimelb.edu.au/__data/assets/image/0029/75890/varieties/160w.jpg 160w,https://pursuit.unimelb.edu.au/__data/assets/image/0029/75890/varieties/375w.jpg 375w,https://pursuit.unimelb.edu.au/__data/assets/image/0029/75890/varieties/768w.jpg 768w,https://pursuit.unimelb.edu.au/__data/assets/image/0029/75890/varieties/960w.jpg 960w,https://pursuit.unimelb.edu.au/__data/assets/image/0029/75890/varieties/1280w.jpg 1280w,https://pursuit.unimelb.edu.au/__data/assets/image/0029/75890/varieties/1440w.jpg 1440w,https://pursuit.unimelb.edu.au/__data/assets/image/0029/75890/varieties/1920w.jpg 1920w\" src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0029/75890/AI-apocalypse-or-overblown-hype_ebfb1d03-837e-428c-b52e-0f972e5a269a.jpg\" alt   data-v-012796f8><figcaption class=\"ps-figure__caption\" data-v-012796f8>AI can propagate misinformation, deepfakes and prejudice. Picture: Getty Images</figcaption></figure></div><span><p>These algorithms absorb and transmit prejudices from the data used to train them.</p><p>Researchers like <a href=\"https://nymag.com/intelligencer/article/ai-artificial-intelligence-chatbots-emily-m-bender.html\" target=\"_self\">Emily Bender</a> and <a href=\"https://www.wired.com/story/google-timnit-gebru-ai-what-really-happened/\" target=\"_self\">Timnit Gebru</a> (who was forced out of Google after raising ethical concerns about AI bias) have spoken out about how AI can propagate <a href=\"https://theconversation.com/ai-tools-are-generating-convincing-misinformation-engaging-with-them-means-being-on-high-alert-202062\" target=\"_self\">misinformation</a>, <a href=\"https://www.abc.net.au/news/2023-05-08/generative-artificial-intelligence-ai-deepfakes-four-corners/102288216\" target=\"_self\">deepfakes</a> and prejudice.</p><p>For example, asking generative AI for the pronoun of a doctor in a short story is likely to return ‘he’ rather than ‘she’ or ‘they’, mirroring prejudices in society. This and other biases show up in many algorithms like those <a href=\"https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing\" target=\"_self\">determining who gets bail</a> and <a href=\"https://link.springer.com/article/10.1007/s00146-023-01686-1#cite\" target=\"_self\">generating images</a> based on text descriptions.</p></span><!--[--><!--noindex--><article class=\"ps-cta container\" data-component=\"CallToAction\" data-v-1d83364b><div class=\"ps-cta__flex\" data-v-1d83364b><div data-v-1d83364b><img src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0024/77145/varieties/375w.jpg\" data-v-1d83364b></div></div><div class=\"ps-cta__info\" data-v-1d83364b><div class=\"ps-cta__top\" data-v-1d83364b><p class=\"ps-cta__channel ps-ff-source-sans-pro ps-fw-semibold ps-text-uppercase\" data-v-1d83364b>Education</p></div><a class=\"ps-cta__link ps-ff-source-sans-pro ps-fw-semibold ps-lh-120 ps-cta__black\" href=\"https://pursuit.unimelb.edu.au/articles/ai-means-a-rethink-of-teaching-foreign-languages?in_c=in_article_cta\" target=\"_self\" data-v-1d83364b><p data-v-1d83364b>AI means a rethink of teaching foreign languages <i class=\"ps-icon--arrow-right ps-cta__black\" data-v-1d83364b></i></p></a></div></article><!--endnoindex--><!--]--><span><p>Some AI Ethics proponents suggest that most people in the AI Alignment camp represent a narrow slice of humanity. Many, they say, are <a href=\"https://qz.com/940660/tech-is-overwhelmingly-male-and-men-are-just-fine-with-that\" target=\"_self\">wealthy white men</a> with something to gain from playing up the <a href=\"https://www.cnbc.com/2023/05/24/ai-poses-existential-risk-former-google-ceo-eric-schmidt-says.html\" target=\"_self\">existential risks</a> while downplaying AI’s effects on <a href=\"https://blogs.icrc.org/law-and-policy/2018/08/28/impact-gender-race-bias-ai/\" target=\"_self\">minoritised groups</a>.</p><p><a href=\"https://www.shunryugarvey.com/2020/08/06/hello-world-2/\" target=\"_self\">Some commentators</a> go as far as saying we should stop discussing the alleged risks of extremely intelligent AI. They say there are more urgent matters to attend to, including how AI might harm non-human <a href=\"https://link.springer.com/article/10.1007/s13347-023-00627-6\" target=\"_self\">animals</a> and the <a href=\"https://gizmodo.com/chatgpt-app-ai-is-generative-ai-bad-for-the-environment-1850481190\" target=\"_self\">environment</a>.</p></span><span><h2 class=\"center\">We need to consider a range of risks</h2></span><span><p>Each camp agrees we have reached a turning point in AI’s ability to impact the world for better and worse.</p></span><div class=\"container\" data-v-012796f8><figure class=\"ps-figure\" data-v-012796f8><img loading=\"lazy\" class=\"ps-figure__image\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://pursuit.unimelb.edu.au/__data/assets/image/0031/75892/varieties/64w.jpg 64w,https://pursuit.unimelb.edu.au/__data/assets/image/0031/75892/varieties/160w.jpg 160w,https://pursuit.unimelb.edu.au/__data/assets/image/0031/75892/varieties/375w.jpg 375w,https://pursuit.unimelb.edu.au/__data/assets/image/0031/75892/varieties/768w.jpg 768w,https://pursuit.unimelb.edu.au/__data/assets/image/0031/75892/varieties/960w.jpg 960w,https://pursuit.unimelb.edu.au/__data/assets/image/0031/75892/varieties/1280w.jpg 1280w,https://pursuit.unimelb.edu.au/__data/assets/image/0031/75892/varieties/1440w.jpg 1440w,https://pursuit.unimelb.edu.au/__data/assets/image/0031/75892/varieties/1920w.jpg 1920w\" src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0031/75892/AI-apocalypse-or-overblown-hype_dd0fad86-e7cd-45ff-a7bd-6e01fd8b0601.jpg\" alt   data-v-012796f8><figcaption class=\"ps-figure__caption\" data-v-012796f8>Professionals in many sectors are already integrating tools like Google’s Bard into their work. Picture: Getty Images</figcaption></figure></div><span><p>Despite the <a href=\"https://www.newindianexpress.com/business/2023/mar/30/musks-letter-a-hot-mess-of-ai-hype-say-critics-2561049.html\" target=\"_self\">heat in these disputes</a>, both camps raise issues worth pondering.</p><p>Maybe we should accept some lessons from each side. For example, we could address the immediate <a href=\"https://www.procon.org/headlines/artificial-intelligence-ai-top-3-pros-and-cons/\" target=\"_self\">social</a> and <a href=\"https://www.oecd-events.org/cop27/session/f174ec37-5145-ed11-819a-00224880a4d8/what-is-the-environmental-footprint-of-artificial-intelligence-\" target=\"_self\">environmental</a> impacts of AI while also continuing to think about possible future safety issues created by more advanced AI.</p><p>Clearly, public interest in AI is escalating.</p><p><a href=\"https://www.minister.industry.gov.au/ministers/husic/media-releases/critical-technologies-securing-australias-future\" target=\"_self\">Politicians</a> and <a href=\"https://www.whitehouse.gov/ostp/ai-bill-of-rights/\" target=\"_self\">governments</a> too are turning their attention to AI. Since AI <a href=\"https://www.industry.gov.au/publications/critical-technologies-statement\" target=\"_self\">promises both significant benefits and dangers</a>, this interest is welcome.</p><p>Whichever camp of concern speaks to you most, there is a clear and pressing need for research that considers how to ethically evolve AI.</p><p>Banner: Getty Images</p></span></div>\n<p>This article was first published on <a href=\"https://pursuit.unimelb.edu.au\">Pursuit</a>. <a href=\"https://pursuit.unimelb.edu.au/articles/ai-apocalypse-or-overblown-hype\">Read the original article.</a></p>","date_published":"2023-06-14T14:40:25+10:00","date_updated":"2023-06-14T14:40:25+10:00","url":"https://pursuit.unimelb.edu.au/articles/ai-apocalypse-or-overblown-hype","title":"AI apocalypse or overblown hype?","summary":"Based on the speed at which artificial intelligence (AI) is developing, it’s imperative we understand, and act on, the potential risks it poses","org_objects":[],"tag_objects":[],"author_objects":[{"name":"Dr Simon Coghlan","url":"https:\\/\\/pursuit.unimelb.edu.au\\/individuals\\/dr-simon-coghlan","orcid":"","fae_url":"https://findanexpert.unimelb.edu.au/profile/787891-simon-coghlan","email":""},{"name":"Dr Shaanan Cohney","url":"https:\\/\\/pursuit.unimelb.edu.au\\/individuals\\/dr-shaanan-cohney","orcid":"","fae_url":"https://findanexpert.unimelb.edu.au/profile/640004-shaanan-cohney","email":""}],"citation_objects":[{"credentials":"Dr Simon Coghlan"},{"credentials":"Dr Shaanan Cohney"}]}