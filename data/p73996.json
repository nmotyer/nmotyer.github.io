{"dataset":"articles","provider":"pursuit","banner_url":"https://pursuit.unimelb.edu.au/__data/assets/image/0036/73998/When-AI-gets-it-wrong,-workers-suffer-_ee8d6ef1-f917-4c12-90fa-d4b143d3fea5.jpg","id":"73996","text":"<div class=\"container\"><span><p>Amazon thought it had found an efficient way to find the best workers. Recruitment is time consuming and expensive, so why not outsource it to artificial intelligence (AI)?</p><p>Their team built an AI-based algorithm – a series of instructions telling a computer how to analyse data – that would give each candidate a score from one to five stars. They could then simply choose the candidates with five stars.</p></span><div class=\"container\" data-v-012796f8><figure class=\"ps-figure\" data-v-012796f8><img loading=\"lazy\" class=\"ps-figure__image\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://pursuit.unimelb.edu.au/__data/assets/image/0036/73998/varieties/64w.jpg 64w,https://pursuit.unimelb.edu.au/__data/assets/image/0036/73998/varieties/160w.jpg 160w,https://pursuit.unimelb.edu.au/__data/assets/image/0036/73998/varieties/375w.jpg 375w,https://pursuit.unimelb.edu.au/__data/assets/image/0036/73998/varieties/768w.jpg 768w,https://pursuit.unimelb.edu.au/__data/assets/image/0036/73998/varieties/960w.jpg 960w,https://pursuit.unimelb.edu.au/__data/assets/image/0036/73998/varieties/1280w.jpg 1280w,https://pursuit.unimelb.edu.au/__data/assets/image/0036/73998/varieties/1440w.jpg 1440w,https://pursuit.unimelb.edu.au/__data/assets/image/0036/73998/varieties/1920w.jpg 1920w\" src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0036/73998/When-AI-gets-it-wrong,-workers-suffer-_ee8d6ef1-f917-4c12-90fa-d4b143d3fea5.jpg\" alt   data-v-012796f8><figcaption class=\"ps-figure__caption\" data-v-012796f8>Amazon’s artificial intelligence recruitment algorithm was biased against women. Picture: Getty Images </figcaption></figure></div><span><p><a href=\"https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G/?utm_source=morning_brew\" target=\"_self\">But there was a problem</a>. It turned out that women didn’t score well for software and tech jobs. What was going on?</p><p>Well, the algorithm was trained on CVs submitted to Amazon over the previous 10 years, and most came from men. The algorithm had ‘learned’ that men were to be preferred. It awarded more stars for masculine language in a CV and took off stars for anyone who went to a women’s college.</p><p>The algorithm had been taught to discriminate, copying human bias.</p></span><!--[--><!--noindex--><article class=\"ps-cta container\" data-component=\"CallToAction\" data-v-1d83364b><div class=\"ps-cta__flex\" data-v-1d83364b><div data-v-1d83364b><img src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0031/75883/varieties/375w.jpg\" data-v-1d83364b></div></div><div class=\"ps-cta__info\" data-v-1d83364b><div class=\"ps-cta__top\" data-v-1d83364b><p class=\"ps-cta__channel ps-ff-source-sans-pro ps-fw-semibold ps-text-uppercase\" data-v-1d83364b>Politics &amp; Society</p></div><a class=\"ps-cta__link ps-ff-source-sans-pro ps-fw-semibold ps-lh-120 ps-cta__black\" href=\"https://pursuit.unimelb.edu.au/articles/ai-apocalypse-or-overblown-hype?in_c=in_article_cta\" target=\"_self\" data-v-1d83364b><p data-v-1d83364b>AI apocalypse or overblown hype? <i class=\"ps-icon--arrow-right ps-cta__black\" data-v-1d83364b></i></p></a></div></article><!--endnoindex--><!--]--><span><p><a href=\"https://pursuit.unimelb.edu.au/articles/when-it-comes-to-jobs-ai-does-not-like-parents\" target=\"_self\">Other studies</a> have found that AI can pick up gender signals in a CV, even when a name and pronouns are removed. And, even if AI is trained to be gender-neutral, it might still discriminate against parents or other vulnerable employee groups, like those who are racially or culturally diverse or LGBTQI+.</p><p>But most cases of AI-based discrimination won’t be reported. Or maybe even noticed. And that is a big problem.</p><p>In a <a href=\"https://law.unimelb.edu.au/__data/assets/pdf_file/0010/4805047/02-Blackham-62.pdf\" target=\"_self\">detailed analysis of Australian workplace laws</a>, published in the <a href=\"https://law.unimelb.edu.au/mulr\" target=\"_self\" class=\"italics\">Melbourne University Law Review</a>, I found there is little known about how Australian employers are using AI.</p><p>There are many software tools that use AI to streamline human resource functions – from recruitment to performance management and even to dismissal. But how these are being used is often only revealed when things go really wrong.</p><p>For example, the Australian Public Service tried using AI-assisted technology to manage promotions. Many of these promotions were <a href=\"https://www.mpc.gov.au/sites/default/files/2022-10/Annual Report 2021-22.pdf\" target=\"_self\">later overturned</a> for not being based on merit, but this was only revealed because the Public Service has a dedicated Merit Protection Commissioner.</p></span><div class=\"container\" data-v-012796f8><figure class=\"ps-figure\" data-v-012796f8><img loading=\"lazy\" class=\"ps-figure__image\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://pursuit.unimelb.edu.au/__data/assets/image/0014/74003/varieties/64w.jpg 64w,https://pursuit.unimelb.edu.au/__data/assets/image/0014/74003/varieties/160w.jpg 160w,https://pursuit.unimelb.edu.au/__data/assets/image/0014/74003/varieties/375w.jpg 375w,https://pursuit.unimelb.edu.au/__data/assets/image/0014/74003/varieties/768w.jpg 768w,https://pursuit.unimelb.edu.au/__data/assets/image/0014/74003/varieties/960w.jpg 960w,https://pursuit.unimelb.edu.au/__data/assets/image/0014/74003/varieties/1280w.jpg 1280w,https://pursuit.unimelb.edu.au/__data/assets/image/0014/74003/varieties/1440w.jpg 1440w,https://pursuit.unimelb.edu.au/__data/assets/image/0014/74003/varieties/1920w.jpg 1920w\" src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0014/74003/When-AI-gets-it-wrong,-workers-suffer-_c3ae4df0-f28a-4171-8c6b-371bf5df6721.jpg\" alt   data-v-012796f8><figcaption class=\"ps-figure__caption\" data-v-012796f8>The Australian Public Service tried using AI-assisted technology to manage promotions, but many were overturned. Picture: Getty Images </figcaption></figure></div><span><p>What happens in the private sector, where most people work?</p><p>Europe has strong privacy and data protection laws – the <a href=\"https://gdpr-info.eu/art-22-gdpr/\" target=\"_self\">General Data Protection Regulation</a> (GDPR) – that demand a human decision-maker have the final say in any automated process that significantly affects people’s lives. In the EU, gig workers have used this to <a href=\"https://eulawanalysis.blogspot.com/2021/04/the-ola-uber-judgments-for-first-time.html\" target=\"_self\">challenge Uber and Ola</a> when they were automatically terminated as drivers.</p><p>But Australia has no equivalent.</p></span><!--[--><!--noindex--><article class=\"ps-cta container\" data-component=\"CallToAction\" data-v-1d83364b><div class=\"ps-cta__flex\" data-v-1d83364b><div data-v-1d83364b><img src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0028/76861/varieties/375w.jpg\" data-v-1d83364b></div></div><div class=\"ps-cta__info\" data-v-1d83364b><div class=\"ps-cta__top\" data-v-1d83364b><p class=\"ps-cta__channel ps-ff-source-sans-pro ps-fw-semibold ps-text-uppercase\" data-v-1d83364b>Politics &amp; Society</p></div><a class=\"ps-cta__link ps-ff-source-sans-pro ps-fw-semibold ps-lh-120 ps-cta__black\" href=\"https://pursuit.unimelb.edu.au/articles/ai-automation-and-women?in_c=in_article_cta\" target=\"_self\" data-v-1d83364b><p data-v-1d83364b>AI, automation and women <i class=\"ps-icon--arrow-right ps-cta__black\" data-v-1d83364b></i></p></a></div></article><!--endnoindex--><!--]--><span><p>Australian privacy law significantly lags behind countries like the UK and the European Union. Incredibly, it contains a blanket exception for ‘employee records’ – while your employer needs your consent to initially gather new data, there are no limits placed on that data once it is held.</p><p>And the federal <a href=\"https://www.legislation.gov.au/Details/C2014C00076\" target=\"_self\" class=\"italics\">Privacy Act 1988</a><a href=\"https://www.legislation.gov.au/Details/C2014C00076\" target=\"_self\"> (Cth)</a> does not apply to small businesses, which employ most Australian workers.</p><p>Discrimination law might fill this gap if it can be shown that an AI algorithm discriminates against certain people or groups. But if we don’t know that an algorithm is being used, how do we challenge it?</p><p>Discrimination law mostly relies on individuals making a complaint – and few people do, even when they know they have been discriminated against. With automated decisions, we may not even know what algorithm has been used, let alone if it is discriminating against us.</p><p>We need reform – and soon. As we watch the management of OpenAI (makers of ChatGPT) <a href=\"https://www.theguardian.com/business/2023/nov/23/openai-was-working-on-advanced-model-so-powerful-it-alarmed-staff\" target=\"_self\">implode over fears</a> of where the technology is going, it is clear we need strong regulation of new AI technologies. We cannot rely on the companies themselves to have the answers or call for help when needed, much less to publicly report any serious problems.</p></span><div class=\"container\" data-v-012796f8><figure class=\"ps-figure\" data-v-012796f8><img loading=\"lazy\" class=\"ps-figure__image\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://pursuit.unimelb.edu.au/__data/assets/image/0012/74001/varieties/64w.jpg 64w,https://pursuit.unimelb.edu.au/__data/assets/image/0012/74001/varieties/160w.jpg 160w,https://pursuit.unimelb.edu.au/__data/assets/image/0012/74001/varieties/375w.jpg 375w,https://pursuit.unimelb.edu.au/__data/assets/image/0012/74001/varieties/768w.jpg 768w,https://pursuit.unimelb.edu.au/__data/assets/image/0012/74001/varieties/960w.jpg 960w,https://pursuit.unimelb.edu.au/__data/assets/image/0012/74001/varieties/1280w.jpg 1280w,https://pursuit.unimelb.edu.au/__data/assets/image/0012/74001/varieties/1440w.jpg 1440w,https://pursuit.unimelb.edu.au/__data/assets/image/0012/74001/varieties/1920w.jpg 1920w\" src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0012/74001/When-AI-gets-it-wrong,-workers-suffer-_13174a1b-b019-4d6e-8470-ea6027ba32d1.jpg\" alt   data-v-012796f8><figcaption class=\"ps-figure__caption\" data-v-012796f8>Australia needs to adopt more rigorous privacy law, like the European Union. Picture: Getty Images </figcaption></figure></div><span><p>The Federal government, in its <a href=\"https://www.ag.gov.au/sites/default/files/2023-09/government-response-privacy-act-review-report.PDF\" target=\"_self\">response to the review of the Privacy Act</a>, has agreed in principle to consult on the employee records exception. And it has agreed in principle to (eventually) remove the small business exception.</p><p>But we need more. Adopting rigorous privacy law – like the GDPR – is a first step. But the EU has recognised the need to go further, as it attempts to <a href=\"https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence\" target=\"_self\">pass the new EU AI Act</a>. The Act aims to be the world’s first comprehensive AI law and would impose more regulation for riskier technologies. Employment systems using AI would be classed as high-risk.</p></span><!--[--><!--noindex--><article class=\"ps-cta container\" data-component=\"CallToAction\" data-v-1d83364b><div class=\"ps-cta__flex\" data-v-1d83364b><div data-v-1d83364b><img src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0025/75418/varieties/375w.jpg\" data-v-1d83364b></div></div><div class=\"ps-cta__info\" data-v-1d83364b><div class=\"ps-cta__top\" data-v-1d83364b><p class=\"ps-cta__channel ps-ff-source-sans-pro ps-fw-semibold ps-text-uppercase\" data-v-1d83364b>Sciences &amp; Technology</p></div><a class=\"ps-cta__link ps-ff-source-sans-pro ps-fw-semibold ps-lh-120 ps-cta__black\" href=\"https://pursuit.unimelb.edu.au/articles/when-it-comes-to-jobs-ai-does-not-like-parents?in_c=in_article_cta\" target=\"_self\" data-v-1d83364b><p data-v-1d83364b>When it comes to jobs, AI does not like parents <i class=\"ps-icon--arrow-right ps-cta__black\" data-v-1d83364b></i></p></a></div></article><!--endnoindex--><!--]--><span><p><a href=\"https://law.unimelb.edu.au/__data/assets/pdf_file/0010/4805047/02-Blackham-62.pdf\" target=\"_self\">I have argued</a>, though, that discrimination law also needs an overhaul. Rather than relying on individuals to make a complaint, we need positive, proactive obligations on employers, so it is clear what they are doing, and clear that they must engage with workers before they adopt these new technologies.</p><p>We must demand open reporting on AI development and practices, or we might not find out what we need to know until it is too late.</p><p>Banner: Getty Images</p></span></div>\n<p>This article was first published on <a href=\"https://pursuit.unimelb.edu.au\">Pursuit</a>. <a href=\"https://pursuit.unimelb.edu.au/articles/when-ai-gets-it-wrong-workers-suffer\">Read the original article.</a></p>","date_published":"2023-11-29T05:19:15+11:00","date_updated":"2023-11-29T05:19:15+11:00","url":"https://pursuit.unimelb.edu.au/articles/when-ai-gets-it-wrong-workers-suffer","title":"When AI gets it wrong, workers suffer","summary":"AI can be just as discriminatory in the workplace as any human manager and the law needs to catch up to this new reality","org_objects":[],"tag_objects":[],"author_objects":[{"name":"Associate Professor Alysia Blackham","url":"https:\\/\\/pursuit.unimelb.edu.au\\/individuals\\/associate-professor-alysia-blackham","orcid":"","fae_url":"http://www.findanexpert.unimelb.edu.au/display/person97769","email":""}],"citation_objects":[{"credentials":"Associate Professor Alysia Blackham"}]}