{"dataset":"articles","provider":"pursuit","banner_url":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=","id":"73212","text":"<div class=\"container\"><span><p>Taylor Swift’s <a href=\"https://www.abc.net.au/news/2024-01-27/how-ai-is-creating-taylor-swift-pornographic-deepfakes/103396284\" target=\"_self\">ordeal</a> at the hands of deepfake pornographers has spotlighted the ugly, misogynistic practice of humiliating women (<a href=\"https://www.abc.net.au/news/2019-08-30/deepfake-revenge-porn-noelle-martin-story-of-image-based-abuse/11437774\" target=\"_self\">and they are mostly women</a>) by creating and distributing fake images of them performing sexual acts.</p><p>If you haven’t heard of them, deepfakes are images, videos or audio that falsely present real people saying or doing things they did not do.</p><p>Deepfakes are created by an artificial intelligence (AI) technique called deep learning that manipulates aspects of existing material (or even uses generative AI to create ‘new’ footage) of things that never actually happened.</p><p>And the results can be quite convincing.</p></span><div data-component=\"VideoBlock\" ><div class=\"container\" data-v-4bbde884><div class=\"row\" data-v-4bbde884><div class=\"col-12\" data-v-4bbde884><figure class=\"ps-figure ps-figure--full-width\" data-v-4bbde884><div class=\"ps-embed-video__wrapper\" data-v-4bbde884><a href=\"https://www.youtube.com/embed/yCMqcFAigRg?autoplay=1&amp;rel=0\" id=\"vidlink\" class=\"ps-embed-video__link\" data-v-4bbde884><div class=\"ps-embed-video\" style=\"max-width:845px;max-height:480px;\" data-v-4bbde884><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=\" alt style=\"background-image:url(https://i.ytimg.com/vi/yCMqcFAigRg/maxresdefault.jpg?&amp;enablejsapi=1);max-width:845px;max-height:480px;\" data-v-4bbde884><div class=\"ps-embed-video__play-button\" data-v-4bbde884><svg id=\"playButtonSVG\" xmlns=\"http://www.w3.org/2000/svg\"   viewBox=\"0 0 128 128\" fill=\"none\"><rect id=\"playButtonRect\"   rx=\"64\" fill=\"black\"></rect><path id=\"playButtonPath\" d=\"M42.666 100.934V26.2676L101.333 63.6009L42.666 100.934ZM50.666 86.4009L86.5327 63.6009L50.666 40.8009V86.4009Z\"></path></svg></div><div class=\"ps-embed-video__video-title\" style=\"display:none;\" data-v-4bbde884><span class=\"ps-embed-video__title\" data-v-4bbde884></span><span class=\"ps-embed-video__duration\" data-v-4bbde884></span></div></div><div class=\"ps-embed-video__iframe-wrapper\" style=\"display:none;\" data-v-4bbde884><iframe class=\"\" src   frameborder=\"0\" allow=\"autoplay\" allowfullscreen id=\"widget2\" title=\"Augmented Reality: Getting under the skin\" data-v-4bbde884></iframe></div></a></div><figcaption class=\"ps-figure__caption\" data-v-4bbde884>WATCH: Picture to Burn by Taylor Swift. Video: YouTube</figcaption></figure></div></div></div></div><span><p>One of the deepfake images targeting Taylor Swift totalled almost 47 million views before <a href=\"https://www.smh.com.au/world/north-america/deepfake-pornographic-images-of-taylor-swift-circulated-online-her-fans-are-fighting-back-20240127-p5f0fm.html\" target=\"_self\">Swift’s fans mobilised and reported the fake en masse</a>. Even the White House got involved, <a href=\"https://abcnews.go.com/US/white-house-calls-legislation-regulate-ai-amid-explicit/story?id=106718520#:~:text=\"We are alarmed by the,House Correspondent Karen L. Travers.\" target=\"_self\">calling it “alarming”</a>.</p><p>AI has been used to create non-consensual pornographic and sexualised images of celebrities, politicians and ordinary individuals. It’s wrong on every level and can cause severe psychological, relationship and career harm.</p><p>And the <a href=\"https://www.abc.net.au/news/2023-10-24/artificial-intelligence-fashion-industry-models-deepfake-porn-ai/102997036\" target=\"_self\">surge in generative AI</a> products just makes this easier.</p><p>Deepfakes can be used to blackmail and intimidate the person falsely represented. Australia’s <a href=\"https://www.esafety.gov.au/industry/tech-trends-and-challenges/deepfakes\" target=\"_self\">E-Safety Commissioner reports</a> that school-aged children are being bullied using deepfake images.</p></span><!--[--><!--noindex--><article class=\"ps-cta container\" data-component=\"CallToAction\" data-v-1d83364b><div class=\"ps-cta__flex\" data-v-1d83364b><div data-v-1d83364b><img alt src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0019/73216/varieties/375w.jpg\" data-v-1d83364b></div></div><div class=\"ps-cta__info\" data-v-1d83364b><!--v-if--><a class=\"ps-cta__link ps-ff-source-sans-pro ps-fw-semibold ps-lh-120 ps-cta__black\" href=\"https://swiftposium2024.com/?ex_c=in_article_cta\" target=\"_self\" data-v-1d83364b><p data-v-1d83364b>Swiftposium 2024 <i class=\"ps-icon--arrow-right ps-cta__black\" data-v-1d83364b></i></p></a></div></article><!--endnoindex--><!--]--><span><p>Deepfake images, <a href=\"https://news.rthk.hk/rthk/en/video-gallery.htm?vid=1739119\" target=\"_self\">video and voices</a> may also be used for <a href=\"https://www.sciencefocus.com/future-technology/ai-deepfake-scam-calls\" target=\"_self\">scams and fraud</a> or to undermine the <a href=\"https://www.science.org/content/article/how-spot-deepfake-and-prevent-it-causing-political-chaos\" target=\"_self\">credibility of public figures</a> and <a href=\"https://www.unswlawjournal.unsw.edu.au/article/disinformation-deepfakes-and-democracies-the-need-for-legislative-reform\" target=\"_self\">manipulate political processes</a>.</p><p>But are they illegal? And does the legal system offer any redress to targets in the increasingly Wild West of the internet?</p><p>It has been reported that Taylor Swift is <a href=\"https://www.usatoday.com/story/news/nation/2024/01/26/was-deepfake-taylor-swift-pornography-illegal-can-she-sue/72359653007/\" target=\"_self\">considering suing</a> in response to the non-consensual and sexually explicit deepfake images of her recently released online and that US lawmakers are considering <a href=\"https://www.theguardian.com/technology/2024/jan/30/taylor-swift-ai-deepfake-nonconsensual-sexual-images-bill\" target=\"_self\">new criminal offences</a> to tackle the issue.</p><p>In Australia, state and territory criminal law (other than in Tasmania) contains specific offences for <a href=\"https://link.springer.com/chapter/10.1007/978-3-030-83734-1_29#Sec3\" target=\"_self\">intimate image abuse</a>, which may capture deepfake images.</p><p>In Victoria, for example, it’s an offence to intentionally <a href=\"https://classic.austlii.edu.au/au/legis/vic/consol_act/ca195882/s53r.html\" target=\"_self\">produce</a>, <a href=\"https://classic.austlii.edu.au/au/legis/vic/consol_act/ca195882/s53s.html\" target=\"_self\">distribute</a> or <a href=\"https://classic.austlii.edu.au/au/legis/vic/consol_act/ca195882/s53t.html\" target=\"_self\">threaten to distribute</a> an intimate image depicting another person where the image is “contrary to community standards of acceptable conduct”.</p><p>Of course, criminal law often fails to provide justice to the victims of deepfake images because the people who created and shared them – the perpetrators – cannot be found or traced.</p><p>Another response is to ensure the images are removed as quickly as possible from social media or websites. This was done in the Taylor Swift case, when <a href=\"https://www.reuters.com/technology/x-lifts-ban-taylor-swift-searches-after-explicit-fake-images-spread-wsj-2024-01-30/\" target=\"_self\">X temporarily restricted searches</a> using her name following the pressure of thousands of her fans.</p></span><div class=\"container\" data-v-012796f8><figure class=\"ps-figure\" data-v-012796f8><img loading=\"lazy\" class=\"ps-figure__image\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://pursuit.unimelb.edu.au/__data/assets/image/0020/73217/varieties/64w.jpg 64w,https://pursuit.unimelb.edu.au/__data/assets/image/0020/73217/varieties/160w.jpg 160w,https://pursuit.unimelb.edu.au/__data/assets/image/0020/73217/varieties/375w.jpg 375w,https://pursuit.unimelb.edu.au/__data/assets/image/0020/73217/varieties/768w.jpg 768w,https://pursuit.unimelb.edu.au/__data/assets/image/0020/73217/varieties/960w.jpg 960w,https://pursuit.unimelb.edu.au/__data/assets/image/0020/73217/varieties/1280w.jpg 1280w,https://pursuit.unimelb.edu.au/__data/assets/image/0020/73217/varieties/1440w.jpg 1440w,https://pursuit.unimelb.edu.au/__data/assets/image/0020/73217/varieties/1920w.jpg 1920w\" src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0020/73217/93294c1485215cc1399e856fe77682e5f40c22f3.jpg\" alt   data-v-012796f8><figcaption class=\"ps-figure__caption\" data-v-012796f8>Taylor Swift is reportedly considering suing in response to the non-consensual deepfakes. Picture: Getty Images </figcaption></figure></div><span><p>But most victims aren’t Taylor Swift and even those who are famous, are <a href=\"https://www.nbcnews.com/tech/misinformation/teen-marvel-star-xochitl-gomez-speaks-deepfake-rcna134753\" target=\"_self\">less fortunate</a>.</p><p>In Australia, victims of offensive deepfake images <a href=\"https://www.esafety.gov.au/report\" target=\"_self\">can request</a> that platforms and websites remove the images, although they will not usually have a massive public movement behind them.</p><p>The E-Safety Commissioner <a href=\"https://www.esafety.gov.au/sites/default/files/2022-03/Compliance and Enforcement Policy.pdf\" target=\"_self\">has the power</a> to demand they be taken down. But by then it may be too late.</p></span><!--[--><!--noindex--><article class=\"ps-cta container\" data-component=\"CallToAction\" data-v-1d83364b><div class=\"ps-cta__flex\" data-v-1d83364b><div data-v-1d83364b><img src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0023/73256/varieties/375w.jpg\" data-v-1d83364b></div></div><div class=\"ps-cta__info\" data-v-1d83364b><div class=\"ps-cta__top\" data-v-1d83364b><p class=\"ps-cta__channel ps-ff-source-sans-pro ps-fw-semibold ps-text-uppercase\" data-v-1d83364b>Arts &amp; Culture</p></div><a class=\"ps-cta__link ps-ff-source-sans-pro ps-fw-semibold ps-lh-120 ps-cta__black\" href=\"https://pursuit.unimelb.edu.au/articles/the-man-taylor-s-feminism-could-go-so-much-further?in_c=in_article_cta\" target=\"_self\" data-v-1d83364b><p data-v-1d83364b>‘The Man’: Taylor’s feminism could go so much further <i class=\"ps-icon--arrow-right ps-cta__black\" data-v-1d83364b></i></p></a></div></article><!--endnoindex--><!--]--><span><p>Notably, even in the Taylor Swift case, the offending images were purportedly shared millions of times before this happened.</p><p>The <a href=\"https://www8.austlii.edu.au/cgi-bin/viewdoc/au/legis/cth/consol_act/osa2021154/s75.html\" target=\"_self\">Online Safety Act 2021</a> (Cth) imposes civil penalties on those who fail to comply with take down orders or post intimate images without consent, including deepfake images. The penalty is up to <a href=\"https://www.accc.gov.au/business/compliance-and-enforcement/fines-and-penalties#:~:text=Penalty amount&text=The value of a penalty,value from 1 July 2023.\" target=\"_self\">500 units</a> or $AU156,500.</p><p>Civil penalties are a kind of fine – money paid by the wrongdoer to the Commonwealth. The payment is aimed at <a href=\"https://pursuit.unimelb.edu.au/articles/they-re-using-my-face\" target=\"_self\">deterring the wrongdoing</a> simply by making the cost of the conduct prohibitively high.</p><p>But the penalty does not get paid to the victim, and they may still wish to seek compensation or vindication for the harm done.</p><p>It is unclear if Taylor Swift will sue or who she will sue.</p><p>In Australia, deepfake victims have limited possible causes to seek damages via civil action. Again, in most cases, the victim will not be able to find the wrongdoer who created the non-consensual pornographic image.</p><p>This means the most viable defendant will be the platform that hosted the image, or the tech company that produced the technology to create the deepfake.</p></span><div class=\"container\" data-v-012796f8><figure class=\"ps-figure\" data-v-012796f8><img loading=\"lazy\" class=\"ps-figure__image\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://pursuit.unimelb.edu.au/__data/assets/image/0014/73220/varieties/64w.jpg 64w,https://pursuit.unimelb.edu.au/__data/assets/image/0014/73220/varieties/160w.jpg 160w,https://pursuit.unimelb.edu.au/__data/assets/image/0014/73220/varieties/375w.jpg 375w,https://pursuit.unimelb.edu.au/__data/assets/image/0014/73220/varieties/768w.jpg 768w,https://pursuit.unimelb.edu.au/__data/assets/image/0014/73220/varieties/960w.jpg 960w,https://pursuit.unimelb.edu.au/__data/assets/image/0014/73220/varieties/1280w.jpg 1280w,https://pursuit.unimelb.edu.au/__data/assets/image/0014/73220/varieties/1440w.jpg 1440w,https://pursuit.unimelb.edu.au/__data/assets/image/0014/73220/varieties/1920w.jpg 1920w\" src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0014/73220/73807468ed4e20447b3b1f07255b0ccb5d4f7028.jpg\" alt   data-v-012796f8><figcaption class=\"ps-figure__caption\" data-v-012796f8>Deepfake technology has legitimate uses, but when used to harm, victims have limited possible causes to seek damages via civil action. Picture: Getty Images</figcaption></figure></div><span><p>In the US, digital platforms are <a href=\"https://www.billboard.com/business/legal/taylor-swift-deepfakes-illegal-stopped-1235593162/\" target=\"_self\">shielded</a> from this kind of liability by <a href=\"https://www.pbs.org/newshour/politics/what-you-should-know-about-section-230-the-rule-that-shaped-todays-internet\" target=\"_self\">Section 230 of the Communications Decency Act</a>, although the limits of that immunity are still being explored.</p><p>In Australian law, a platform or website can be directly liable for <a href=\"https://www.theguardian.com/media/2021/sep/08/high-court-rules-australian-media-companies-are-liable-for-defamatory-comments-posted-on-their-facebook-pages\" target=\"_self\">hosting defamatory material</a>. Non-consensual <a href=\"https://www.artslaw.com.au/information-sheet/unauthorised-use-of-your-image/#:~:text=Defamation is the law that,to be shunned or avoided.\" target=\"_self\">deepfake pornographic images</a> may be classed as defamatory if they would harm the reputation of the person being shown or expose them to ridicule or contempt.</p><p>There is, unfortunately, still a question around whether a deepfake which is acknowledged as a ‘fake’ would have this effect in law, even though it may still humiliate the victim.</p></span><!--[--><!--noindex--><article class=\"ps-cta container\" data-component=\"CallToAction\" data-v-1d83364b><div class=\"ps-cta__flex\" data-v-1d83364b><div data-v-1d83364b><img src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0022/73183/varieties/375w.jpg\" data-v-1d83364b></div></div><div class=\"ps-cta__info\" data-v-1d83364b><div class=\"ps-cta__top\" data-v-1d83364b><p class=\"ps-cta__channel ps-ff-source-sans-pro ps-fw-semibold ps-text-uppercase\" data-v-1d83364b>Arts &amp; Culture</p></div><a class=\"ps-cta__link ps-ff-source-sans-pro ps-fw-semibold ps-lh-120 ps-cta__black\" href=\"https://pursuit.unimelb.edu.au/articles/fearless-how-taylor-swift-is-owning-her-narrative?in_c=in_article_cta\" target=\"_self\" data-v-1d83364b><p data-v-1d83364b>‘Fearless’: How Taylor Swift is owning her narrative <i class=\"ps-icon--arrow-right ps-cta__black\" data-v-1d83364b></i></p></a></div></article><!--endnoindex--><!--]--><span><p>Moreover, Australia is now introducing <a href=\"https://hwlebsworth.com.au/moving-on-from-voller-stage-2-defamation-reforms-on-the-horizon/\" target=\"_self\">reform to defamation law</a> to <a href=\"https://www.theguardian.com/media/2022/dec/14/defamation-reforms-australian-media-may-not-be-liable-for-facebook-comments-in-future\" target=\"_self\">limit the liability of digital intermediaries</a> in these scenarios.</p><p>This immunity is subject to <a href=\"https://pcc.gov.au/uniform/2023/pcc-584-d05b.pdf\" target=\"_self\">conditions</a> including that the platform have an “accessible complaints mechanism” and “reasonable prevention steps”.</p><p>In cases where deepfake images of celebrities are used to promote <a href=\"https://www.nbcnews.com/tech/tech-news/deepfake-scams-arrived-fake-videos-spread-facebook-tiktok-youtube-rcna101415\" target=\"_self\">scams</a>, particularly <a href=\"https://www.theage.com.au/national/victoria/cryptocurrency-scammers-turn-to-deep-fakes-to-snare-victims-20220318-p5a5un.html\" target=\"_self\">investment scams</a>, the conduct occurs in ‘trade or commerce’.</p><p>Victims of this fraud may be able to claim compensation for the harms caused to them by misleading conduct under the <a href=\"https://consumer.gov.au/australian-consumer-law#:~:text=The protections in the ACL,and the States and Territories.\" target=\"_self\">Australian Consumer Law</a> or <a href=\"https://www5.austlii.edu.au/au/legis/cth/consol_act/asaica2001529/index.html\" target=\"_self\">ASIC Act</a>.</p><p>Of course, as we have already seen, the perpetrator is likely to be hard to find. Which again leaves the platform.</p></span><div class=\"container\" data-v-012796f8><figure class=\"ps-figure\" data-v-012796f8><img loading=\"lazy\" class=\"ps-figure__image\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://pursuit.unimelb.edu.au/__data/assets/image/0022/73219/varieties/64w.jpg 64w,https://pursuit.unimelb.edu.au/__data/assets/image/0022/73219/varieties/160w.jpg 160w,https://pursuit.unimelb.edu.au/__data/assets/image/0022/73219/varieties/375w.jpg 375w,https://pursuit.unimelb.edu.au/__data/assets/image/0022/73219/varieties/768w.jpg 768w,https://pursuit.unimelb.edu.au/__data/assets/image/0022/73219/varieties/960w.jpg 960w,https://pursuit.unimelb.edu.au/__data/assets/image/0022/73219/varieties/1280w.jpg 1280w,https://pursuit.unimelb.edu.au/__data/assets/image/0022/73219/varieties/1440w.jpg 1440w,https://pursuit.unimelb.edu.au/__data/assets/image/0022/73219/varieties/1920w.jpg 1920w\" src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0022/73219/7ac345000c5b9420bfe62ed3879b19bb5bf16379.jpg\" alt   data-v-012796f8><figcaption class=\"ps-figure__caption\" data-v-012796f8>There is talk of introducing mandatory ‘safety’ obligations in Australia and new disclosure obligations in the EU. Picture: Getty Images</figcaption></figure></div><span><p>Test case litigation by the <a href=\"https://www.accc.gov.au/\" target=\"_self\">Australian Competition and Consumer Commission</a> (ACCC) is currently testing the possibility of making digital platforms, in this case Meta, liable for misleading <a href=\"https://www.theguardian.com/technology/2022/mar/18/accc-takes-meta-to-court-over-facebook-scam-ads-depicting-australian-identities\" target=\"_self\">deepfake crypto scams</a>.</p><p>The <a href=\"https://pursuit.unimelb.edu.au/articles/accc-vs-big-tech-round-10-and-counting\" target=\"_self\">ACCC is arguing Meta should be directly liable for misleading conduct</a> because it actively targeted the ads to possible victims. The ACCC is also arguing that Meta should be liable as an accessory to the scammers because it failed promptly to remove the ads, even after they were notified that they were fakes.</p><p>And what about the technology producer who put the generative AI tools used to create the deepfake on the market?</p></span><!--[--><!--noindex--><article class=\"ps-cta container\" data-component=\"CallToAction\" data-v-1d83364b><div class=\"ps-cta__flex\" data-v-1d83364b><div data-v-1d83364b><img src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0012/73200/varieties/375w.jpg\" data-v-1d83364b></div></div><div class=\"ps-cta__info\" data-v-1d83364b><div class=\"ps-cta__top\" data-v-1d83364b><p class=\"ps-cta__channel ps-ff-source-sans-pro ps-fw-semibold ps-text-uppercase\" data-v-1d83364b>Arts &amp; Culture</p></div><a class=\"ps-cta__link ps-ff-source-sans-pro ps-fw-semibold ps-lh-120 ps-cta__black\" href=\"https://pursuit.unimelb.edu.au/articles/dear-john-taylor-s-responsibility-to-her-swifties?in_c=in_article_cta\" target=\"_self\" data-v-1d83364b><p data-v-1d83364b>‘Dear John’: Taylor’s responsibility to her Swifties <i class=\"ps-icon--arrow-right ps-cta__black\" data-v-1d83364b></i></p></a></div></article><!--endnoindex--><!--]--><span><p>The legal question here is whether they have a legal duty to make those tools safe.</p><p>These kinds of ‘<a href=\"https://www.nbcnews.com/tech/tech-news/microsoft-ceo-satya-nadella-calls-taylor-swift-deepfakes-alarming-terr-rcna136402\" target=\"_self\">guard rails</a>’ might include technical interventions to prevent the tool responding to prompts for creating deepfake pornography, more robust content moderation or <a href=\"https://www.wired.com/story/ai-watermarking-misinformation/\" target=\"_self\">watermarking to</a> identify fake and authentic images.</p><p>Some may be doing this voluntarily. There is talk of introducing mandatory ‘safety’ obligations in Australia and new <a href=\"https://ec.europa.eu/commission/presscorner/detail/en/ip_23_6473\" target=\"_self\">disclosure obligations</a> in the EU. However, currently, the producers of generative AI are unlikely to owe a legal duty of care that would oblige them to take these actions.</p><p>And none of the methods are foolproof, and may introduce <a href=\"https://www.technologyreview.com/2024/01/29/1087325/three-ways-we-can-fight-deepfake-porn-taylors-version/\" target=\"_self\">their own concerns</a>.</p><p>We should remember that the core harm of sexually explicit deepfake images arises from a lack of consent and social beliefs that tolerate the weaponisation of intimate images.</p></span><div class=\"container\" data-v-012796f8><figure class=\"ps-figure\" data-v-012796f8><img loading=\"lazy\" class=\"ps-figure__image\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://pursuit.unimelb.edu.au/__data/assets/image/0015/73221/varieties/64w.jpg 64w,https://pursuit.unimelb.edu.au/__data/assets/image/0015/73221/varieties/160w.jpg 160w,https://pursuit.unimelb.edu.au/__data/assets/image/0015/73221/varieties/375w.jpg 375w,https://pursuit.unimelb.edu.au/__data/assets/image/0015/73221/varieties/768w.jpg 768w,https://pursuit.unimelb.edu.au/__data/assets/image/0015/73221/varieties/960w.jpg 960w,https://pursuit.unimelb.edu.au/__data/assets/image/0015/73221/varieties/1280w.jpg 1280w,https://pursuit.unimelb.edu.au/__data/assets/image/0015/73221/varieties/1440w.jpg 1440w,https://pursuit.unimelb.edu.au/__data/assets/image/0015/73221/varieties/1920w.jpg 1920w\" src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0015/73221/5a59a42a82ab9f629d08836671ea10eec4b0a163.jpg\" alt   data-v-012796f8><figcaption class=\"ps-figure__caption\" data-v-012796f8>The Taylor Swift case may be a wake-up call to action for the law to catch up. Picture: Getty Images</figcaption></figure></div><span><p>Sure, people are entitled to create and share sexualised images for their own interest or pleasure. But this should never be confused with the use of non-consensual explicit deep fake images to threaten, exploit and intimidate.</p><p>Right now, Australia’s laws offer victims little in the way of genuine and accessible redress through the legal system. There needs to be a multifaceted response – embracing technical, legal and regulatory domains, as well as community education, including about the offence of intimate image abuse.</p><p>It is not just celebrities who are the victims of deepfake pornography, but the Taylor Swift case may be a wake-up call to action for the law to catch up.</p><p><a href=\"https://swiftposium2024.com/\" target=\"_blank\" class=\"italics\">Swiftposium</a><span class=\"italics\"> is an academic conference for scholars discussing the impact of Taylor Swift. It runs at the University of Melbourne from 11-13 February 2024 with </span><a href=\"https://www.eventbrite.com.au/e/swiftposium-presents-taylor-swift-feminism-and-the-music-industry-tickets-797950079167\" target=\"_blank\" class=\"italics\">public events</a><span class=\"italics\"> on Sunday 11 February and recordings of the keynote presentations available online after the conference.</span></p><p>Banner: Taylor Swift performing her ‘Acoustic Era’ in Kansas City / Getty Images</p></span></div>\n<p>This article was first published on <a href=\"https://pursuit.unimelb.edu.au\">Pursuit</a>. <a href=\"https://pursuit.unimelb.edu.au/articles/picture-to-burn-the-law-probably-won-t-protect-taylor-or-other-women-from-deepfakes\">Read the original article.</a></p>","date_published":"2024-02-08T10:04:25+11:00","date_updated":"2024-02-08T10:04:25+11:00","url":"https://pursuit.unimelb.edu.au/articles/picture-to-burn-the-law-probably-won-t-protect-taylor-or-other-women-from-deepfakes","title":"‘Picture to burn’: The law probably won’t protect Taylor (or other women) from deepfakes","summary":"Legal redress is hard if you fall victim to an AI-generated pornographic and abusive deepfake","org_objects":[],"tag_objects":[],"author_objects":[{"name":"Professor Jeannie Marie Paterson","url":"https:\\/\\/pursuit.unimelb.edu.au\\/individuals\\/professor-jeannie-marie-paterson","orcid":"","fae_url":"http://findanexpert.unimelb.edu.au/display/person220398","email":""}],"citation_objects":[{"credentials":"Professor Jeannie Marie Paterson"}]}