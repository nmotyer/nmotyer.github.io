{"dataset":"articles","provider":"pursuit","banner_url":"https://pursuit.unimelb.edu.au/__data/assets/image/0023/75425/When-it-comes-to-jobs,-AI-does-not-like-parents_c6383fdf-36be-4620-b6c2-4409150e8660.jpg","id":"75417","text":"<div class=\"container\"><span><p>Gender bias is deeply ingrained in hiring and work.</p><p>In Australia, women on average <a href=\"https://www.wgea.gov.au/data-statistics/data-explorer\" target=\"_self\">earn 23 per cent less than men</a>, are <a href=\"https://www.wgea.gov.au/sites/default/files/documents/Recruitment_and_Promotion.pdf\" target=\"_self\">less often invited for a job interview and are evaluated more harshly</a>.</p></span><div class=\"container\" data-v-012796f8><figure class=\"ps-figure\" data-v-012796f8><img loading=\"lazy\" class=\"ps-figure__image\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://pursuit.unimelb.edu.au/__data/assets/image/0023/75425/varieties/64w.jpg 64w,https://pursuit.unimelb.edu.au/__data/assets/image/0023/75425/varieties/160w.jpg 160w,https://pursuit.unimelb.edu.au/__data/assets/image/0023/75425/varieties/375w.jpg 375w,https://pursuit.unimelb.edu.au/__data/assets/image/0023/75425/varieties/768w.jpg 768w,https://pursuit.unimelb.edu.au/__data/assets/image/0023/75425/varieties/960w.jpg 960w,https://pursuit.unimelb.edu.au/__data/assets/image/0023/75425/varieties/1280w.jpg 1280w,https://pursuit.unimelb.edu.au/__data/assets/image/0023/75425/varieties/1440w.jpg 1440w,https://pursuit.unimelb.edu.au/__data/assets/image/0023/75425/varieties/1920w.jpg 1920w\" src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0023/75425/When-it-comes-to-jobs,-AI-does-not-like-parents_c6383fdf-36be-4620-b6c2-4409150e8660.jpg\" alt   data-v-012796f8><figcaption class=\"ps-figure__caption\" data-v-012796f8>Strategies like ‘resume blinding’, which may work for human hirers, do not work for AI. Picture: Getty Images</figcaption></figure></div><span><p><a href=\"https://www.forbes.com/sites/forbeshumanresourcescouncil/2018/04/03/the-benefits-and-shortcomings-of-blind-hiring-in-the-recruitment-process/?sh=112d70fb38a3\" target=\"_self\">Blind resume screening or blind hiring</a>, which hides the applicants’ names from CVs during the application process, is one common strategy used to address this bias. Another uses <a href=\"https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained\" target=\"_self\">machine learning</a> (ML) or <a href=\"https://www.britannica.com/technology/artificial-intelligence\" target=\"_self\">Artificial Intelligence</a> (AI) to streamline at least part of the decision-making. After all, AI should be oblivious to human stereotypes.</p><p>Right? Wrong.</p><p>Our <a href=\"https://aclanthology.org/2022.nlpcss-1.15/\" target=\"_self\">research shows</a> that strategies like ‘resume blinding’, which may work for human hirers, do not work for AI.</p></span><!--[--><!--noindex--><article class=\"ps-cta container\" data-component=\"CallToAction\" data-v-1d83364b><div class=\"ps-cta__flex\" data-v-1d83364b><div data-v-1d83364b><img src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0028/76861/varieties/375w.jpg\" data-v-1d83364b></div></div><div class=\"ps-cta__info\" data-v-1d83364b><div class=\"ps-cta__top\" data-v-1d83364b><p class=\"ps-cta__channel ps-ff-source-sans-pro ps-fw-semibold ps-text-uppercase\" data-v-1d83364b>Politics &amp; Society</p></div><a class=\"ps-cta__link ps-ff-source-sans-pro ps-fw-semibold ps-lh-120 ps-cta__black\" href=\"https://pursuit.unimelb.edu.au/articles/ai-automation-and-women?in_c=in_article_cta\" target=\"_self\" data-v-1d83364b><p data-v-1d83364b>AI, automation and women <i class=\"ps-icon--arrow-right ps-cta__black\" data-v-1d83364b></i></p></a></div></article><!--endnoindex--><!--]--><span><p>That AI replicates the bias inherent in its training data is already well known.</p><p>Amazon, for instance, presented an automatic CV screening system for engineering applicants. The system was <a href=\"https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G\" target=\"_self\">subsequently revealed to be sexist</a> (and swiftly deactivated). It had learnt an association between ‘maleness’ and applicant quality.</p><p>Our research takes a close look at the different levels of gender bias in algorithms in hiring.</p><p>We found that gender signals – much more subtle than a name – are ingested and used by AI, which becomes an increasingly pressing issue with powerful generative AI, like <a href=\"https://openai.com/chatgpt\" target=\"_self\">ChatGPT</a>, on the rise.</p></span><div class=\"container\" data-v-012796f8><figure class=\"ps-figure\" data-v-012796f8><img loading=\"lazy\" class=\"ps-figure__image\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://pursuit.unimelb.edu.au/__data/assets/image/0024/75426/varieties/64w.jpg 64w,https://pursuit.unimelb.edu.au/__data/assets/image/0024/75426/varieties/160w.jpg 160w,https://pursuit.unimelb.edu.au/__data/assets/image/0024/75426/varieties/375w.jpg 375w,https://pursuit.unimelb.edu.au/__data/assets/image/0024/75426/varieties/768w.jpg 768w,https://pursuit.unimelb.edu.au/__data/assets/image/0024/75426/varieties/960w.jpg 960w,https://pursuit.unimelb.edu.au/__data/assets/image/0024/75426/varieties/1280w.jpg 1280w,https://pursuit.unimelb.edu.au/__data/assets/image/0024/75426/varieties/1440w.jpg 1440w,https://pursuit.unimelb.edu.au/__data/assets/image/0024/75426/varieties/1920w.jpg 1920w\" src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0024/75426/When-it-comes-to-jobs,-AI-does-not-like-parents_4e707753-1d3b-43f0-a512-e5db3e239642.jpg\" alt   data-v-012796f8><figcaption class=\"ps-figure__caption\" data-v-012796f8>Our research takes a close look at the different levels of gender bias in algorithms in hiring. Picture: Getty Images</figcaption></figure></div><span><p>We find that gender is so deeply embedded in our society – how we talk, where we work, what we study – that it is near-impossible to gender-blind a CV <a href=\"https://www.unimelb.edu.au/newsroom/news/2020/december/entry-barriers-for-women-are-amplified-by-ai-in-recruitment-algorithms,-study-finds\" target=\"_self\">from AI and humans</a>.</p><p>So, what does this mean? Well, even with our best intentions, the algorithm can pick up your gender. And algorithms that can pick up gender can use it to make predictions when it comes to the quality of an applicant.</p></span><!--[--><!--noindex--><article class=\"ps-cta container\" data-component=\"CallToAction\" data-v-1d83364b><div class=\"ps-cta__flex\" data-v-1d83364b><div data-v-1d83364b><img src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0031/75883/varieties/375w.jpg\" data-v-1d83364b></div></div><div class=\"ps-cta__info\" data-v-1d83364b><div class=\"ps-cta__top\" data-v-1d83364b><p class=\"ps-cta__channel ps-ff-source-sans-pro ps-fw-semibold ps-text-uppercase\" data-v-1d83364b>Politics &amp; Society</p></div><a class=\"ps-cta__link ps-ff-source-sans-pro ps-fw-semibold ps-lh-120 ps-cta__black\" href=\"https://pursuit.unimelb.edu.au/articles/ai-apocalypse-or-overblown-hype?in_c=in_article_cta\" target=\"_self\" data-v-1d83364b><p data-v-1d83364b>AI apocalypse or overblown hype? <i class=\"ps-icon--arrow-right ps-cta__black\" data-v-1d83364b></i></p></a></div></article><!--endnoindex--><!--]--><span><h2 class=\"center\">The parenthood proxy</h2></span><span><p>ChatGPT (currently, the most powerful language-based AI) is impacting so many facets of society at an unprecedented speed that <a href=\"https://futureoflife.org/open-letter/pause-giant-ai-experiments/\" target=\"_self\">developers have called for a halt to AI experiments to better understand its effects and consequences</a>.</p><p>Our recent research looked at gender bias in ChatGPT in the context of hiring for a job and asked it to rate the CVs of applicants.</p><p>We constructed CVs for a range of different occupations. Our CVs were high-quality and highly competitive, but we made two important changes.</p><p>Firstly, we swapped the applicant’s name to signal whether a man or woman was applying for the job. Secondly, we added a parental leave gap for half of our respondents.</p></span><div class=\"container\" data-v-012796f8><figure class=\"ps-figure\" data-v-012796f8><img loading=\"lazy\" class=\"ps-figure__image\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://pursuit.unimelb.edu.au/__data/assets/image/0021/75423/varieties/64w.jpg 64w,https://pursuit.unimelb.edu.au/__data/assets/image/0021/75423/varieties/160w.jpg 160w,https://pursuit.unimelb.edu.au/__data/assets/image/0021/75423/varieties/375w.jpg 375w,https://pursuit.unimelb.edu.au/__data/assets/image/0021/75423/varieties/768w.jpg 768w,https://pursuit.unimelb.edu.au/__data/assets/image/0021/75423/varieties/960w.jpg 960w,https://pursuit.unimelb.edu.au/__data/assets/image/0021/75423/varieties/1280w.jpg 1280w,https://pursuit.unimelb.edu.au/__data/assets/image/0021/75423/varieties/1440w.jpg 1440w,https://pursuit.unimelb.edu.au/__data/assets/image/0021/75423/varieties/1920w.jpg 1920w\" src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0021/75423/When-it-comes-to-jobs,-AI-does-not-like-parents_bb88f47c-33dc-4462-b080-cac3f70949a6.jpg\" alt   data-v-012796f8><figcaption class=\"ps-figure__caption\" data-v-012796f8>The high-quality and highly competitive CVs included a parental leave gap for half the respondents. Picture: Supplied</figcaption></figure></div><span><p>All of our applicants had the same qualifications and job experiences – but some were men, some were women, some were parents and some were not.</p><p>We showed ChatGPT the CVs and asked it to rate how qualified the person was for a job on a scale from zero to 100. We repeated this for six different occupations and 30 times per CV to ensure that our results are robust.</p><p>Here is where something interesting happened.</p></span><!--[--><!--noindex--><article class=\"ps-cta container\" data-component=\"CallToAction\" data-v-1d83364b><div class=\"ps-cta__flex\" data-v-1d83364b><div data-v-1d83364b><img src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0023/80582/varieties/375w.jpg\" data-v-1d83364b></div></div><div class=\"ps-cta__info\" data-v-1d83364b><div class=\"ps-cta__top\" data-v-1d83364b><p class=\"ps-cta__channel ps-ff-source-sans-pro ps-fw-semibold ps-text-uppercase\" data-v-1d83364b>Sciences &amp; Technology</p></div><a class=\"ps-cta__link ps-ff-source-sans-pro ps-fw-semibold ps-lh-120 ps-cta__black\" href=\"https://pursuit.unimelb.edu.au/articles/challenging-decisions-made-by-algorithm?in_c=in_article_cta\" target=\"_self\" data-v-1d83364b><p data-v-1d83364b>Challenging decisions made by algorithm <i class=\"ps-icon--arrow-right ps-cta__black\" data-v-1d83364b></i></p></a></div></article><!--endnoindex--><!--]--><span><p>We found ChatGPT did not rank men’s and women’s CVs any differently. Regardless of our name change, the rankings of our scores were equivalent for the men and women applying for the job.</p><p>But, when we added in a gap for parental leave, we found that ChatGPT ranked our parents lower in every single occupation. This was true for fathers and mothers – a gap for caregiving leave told the algorithm that this person was less qualified for the job.</p><p>Gender bias might be scrubbed from ChatGPT’s predictive capacity, but parenthood is not.</p><p>Why is this important?</p></span><div class=\"container\" data-v-012796f8><figure class=\"ps-figure\" data-v-012796f8><img loading=\"lazy\" class=\"ps-figure__image\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://pursuit.unimelb.edu.au/__data/assets/image/0025/75427/varieties/64w.jpg 64w,https://pursuit.unimelb.edu.au/__data/assets/image/0025/75427/varieties/160w.jpg 160w,https://pursuit.unimelb.edu.au/__data/assets/image/0025/75427/varieties/375w.jpg 375w,https://pursuit.unimelb.edu.au/__data/assets/image/0025/75427/varieties/768w.jpg 768w,https://pursuit.unimelb.edu.au/__data/assets/image/0025/75427/varieties/960w.jpg 960w,https://pursuit.unimelb.edu.au/__data/assets/image/0025/75427/varieties/1280w.jpg 1280w,https://pursuit.unimelb.edu.au/__data/assets/image/0025/75427/varieties/1440w.jpg 1440w,https://pursuit.unimelb.edu.au/__data/assets/image/0025/75427/varieties/1920w.jpg 1920w\" src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0025/75427/When-it-comes-to-jobs,-AI-does-not-like-parents_99531ded-4735-49c9-88b6-fe5da2cdce25.jpg\" alt   data-v-012796f8><figcaption class=\"ps-figure__caption\" data-v-012796f8>We found that ChatGPT ranked our parents lower in every single occupation. Picture: Getty Images</figcaption></figure></div><span><p>Even if ChatGPT is stopped from being gender biased by its developers, this same bias will sneak in through a different mechanism – parenthood. We know that <a href=\"https://www.unwomen.org/en/news/in-focus/csw61/redistribute-unpaid-work\" target=\"_self\">women take on the bulk of caring work in our societies</a> and <a href=\"https://hrnews.co.uk/women-at-greatest-risk-of-career-gap-stigma/\" target=\"_self\">women’s CVs are more likely to have parental leave gaps</a> than men’s.</p><p>While we do not know whether ChatGPT will actually rate CVs in real life, our research shows how easily bias can creep into models and that it’s almost impossible for AI developers to anticipate all of those biases or combinations of variables which lead to bias – especially in complex models like ChatGPT.</p></span><span><h2 class=\"center\">The language liability</h2></span><span><p>Imagine two CVs identical in all aspects but for the identity of the applicant: one was written by a man, one by a woman. If we hide the applicant’s identity from a hiring panel, will there be any room for discrimination?</p><p>Our research shows that the answer is a resounding ‘yes’ – if the hiring panel is AI.</p><p>Analysing the data of 2,000 CVs, we found men and women, in the same occupation, use subtly different language to describe their skills and education.</p><p>For instance, we found that women use significantly more verbs that evoke an impression of low power (like ‘assist’, ‘learn’ or ‘need’) than men.</p></span><div class=\"container\" data-v-012796f8><figure class=\"ps-figure\" data-v-012796f8><img loading=\"lazy\" class=\"ps-figure__image\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://pursuit.unimelb.edu.au/__data/assets/image/0026/75428/varieties/64w.jpg 64w,https://pursuit.unimelb.edu.au/__data/assets/image/0026/75428/varieties/160w.jpg 160w,https://pursuit.unimelb.edu.au/__data/assets/image/0026/75428/varieties/375w.jpg 375w,https://pursuit.unimelb.edu.au/__data/assets/image/0026/75428/varieties/768w.jpg 768w,https://pursuit.unimelb.edu.au/__data/assets/image/0026/75428/varieties/960w.jpg 960w,https://pursuit.unimelb.edu.au/__data/assets/image/0026/75428/varieties/1280w.jpg 1280w,https://pursuit.unimelb.edu.au/__data/assets/image/0026/75428/varieties/1440w.jpg 1440w,https://pursuit.unimelb.edu.au/__data/assets/image/0026/75428/varieties/1920w.jpg 1920w\" src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0026/75428/When-it-comes-to-jobs,-AI-does-not-like-parents_db88e5e3-3f89-4003-96c7-ab78db297f18.jpg\" alt   data-v-012796f8><figcaption class=\"ps-figure__caption\" data-v-012796f8>As they usually take on the bulk of caring duties, women’s CVs are more likely to have parental leave gaps. Picture: Getty Images</figcaption></figure></div><span><p>Now, here’s the problem.</p><p>In a follow-up experiment, our team found that AI representations link these subtle language differences back to gender. It means that machine learning models can identify the gender in a CV even after the names and pronouns are removed.</p><p>If AI can predict gender based on language, it can then use it as a piece of evidence in CV rating.</p></span><span><h2 class=\"center\">A strong policy response</h2></span><span><p>So, what does this mean as we start to integrate AI into our work lives?</p></span><!--[--><!--noindex--><article class=\"ps-cta container\" data-component=\"CallToAction\" data-v-1d83364b><div class=\"ps-cta__flex\" data-v-1d83364b><div data-v-1d83364b><img src=\"https://pursuit.unimelb.edu.au/__data/assets/image/0022/86341/varieties/375w.jpg\" data-v-1d83364b></div></div><div class=\"ps-cta__info\" data-v-1d83364b><div class=\"ps-cta__top\" data-v-1d83364b><p class=\"ps-cta__channel ps-ff-source-sans-pro ps-fw-semibold ps-text-uppercase\" data-v-1d83364b>Sciences &amp; Technology</p></div><a class=\"ps-cta__link ps-ff-source-sans-pro ps-fw-semibold ps-lh-120 ps-cta__black\" href=\"https://pursuit.unimelb.edu.au/articles/data-isn-t-neutral-and-neither-are-decision-algorithms?in_c=in_article_cta\" target=\"_self\" data-v-1d83364b><p data-v-1d83364b>Data isn’t neutral and neither are decision algorithms <i class=\"ps-icon--arrow-right ps-cta__black\" data-v-1d83364b></i></p></a></div></article><!--endnoindex--><!--]--><span><p>Well, our research shows that while ‘blind resume screening’ may work for humans, it doesn’t for AI. Even if we drop all identifying language – the shes, hers and names – other language is signalling gender.</p><p>Careful auditing of biases can remove the most obvious layer of discrimination, but further work needs to be done on proxies that can lead to bias but may not be as obvious.</p><p>Here is where we need regulatory controls in response to this more nuanced understanding of AI’s capacity to discriminate and ensure everyone understands AI is not neutral or fair.</p><p>We all need to do our part to ensure AI that is fair and beneficial to everyone – including women and parents.</p><p>Banner: Getty Images</p></span></div>\n<p>This article was first published on <a href=\"https://pursuit.unimelb.edu.au\">Pursuit</a>. <a href=\"https://pursuit.unimelb.edu.au/articles/when-it-comes-to-jobs-ai-does-not-like-parents\">Read the original article.</a></p>","date_published":"2023-07-23T18:27:14+10:00","date_updated":"2023-07-23T18:27:14+10:00","url":"https://pursuit.unimelb.edu.au/articles/when-it-comes-to-jobs-ai-does-not-like-parents","title":"When it comes to jobs, AI does not like parents","summary":"New research finds that AI doesn’t just discriminate against women in the workforce – but also has a problem with parents","org_objects":[],"tag_objects":[],"author_objects":[{"name":"Dr Lea Frermann","url":"https:\\/\\/pursuit.unimelb.edu.au\\/individuals\\/dr-lea-frermann","orcid":"","fae_url":"https://findanexpert.unimelb.edu.au/profile/835002-lea-frermann","email":""},{"name":"Sheilla Njoto","url":"https:\\/\\/pursuit.unimelb.edu.au\\/individuals\\/sheilla-njoto","orcid":"","fae_url":"","email":""},{"name":"Dr Marc Cheong","url":"https:\\/\\/pursuit.unimelb.edu.au\\/individuals\\/dr-marc-cheong","orcid":"","fae_url":"https://findanexpert.unimelb.edu.au/profile/862627-marc-cheong","email":""},{"name":"Professor Leah Ruppanner","url":"https:\\/\\/pursuit.unimelb.edu.au\\/individuals\\/professor-leah-ruppanner","orcid":"","fae_url":"https://findanexpert.unimelb.edu.au/profile/609199-leah-ruppanner","email":""}],"citation_objects":[{"credentials":"Dr Lea Frermann"},{"credentials":"Sheilla Njoto"},{"credentials":"Dr Marc Cheong"},{"credentials":"Professor Leah Ruppanner"}]}